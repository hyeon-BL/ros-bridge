{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 16:13:15.436754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-23 16:13:15.789269: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-23 16:13:17.135026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/winter/.pyenv/versions/3.7.17/envs/carla-0.9.13-py3.7/lib/python3.7/site-packages/cv2/../../lib64:/home/winter/carla-ros-bridge/install/rviz_carla_plugin/lib:/home/winter/carla-ros-bridge/install/carla_waypoint_types/lib:/home/winter/carla-ros-bridge/install/carla_ros_scenario_runner_types/lib:/home/winter/carla-ros-bridge/install/carla_ackermann_msgs/lib:/home/winter/carla-ros-bridge/install/carla_msgs/lib:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/usr/local/cuda-11.2/lib64/:/usr/local/cuda-11.2/lib64/\n",
      "2025-01-23 16:13:17.135230: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/winter/.pyenv/versions/3.7.17/envs/carla-0.9.13-py3.7/lib/python3.7/site-packages/cv2/../../lib64:/home/winter/carla-ros-bridge/install/rviz_carla_plugin/lib:/home/winter/carla-ros-bridge/install/carla_waypoint_types/lib:/home/winter/carla-ros-bridge/install/carla_ros_scenario_runner_types/lib:/home/winter/carla-ros-bridge/install/carla_ackermann_msgs/lib:/home/winter/carla-ros-bridge/install/carla_msgs/lib:/opt/ros/foxy/opt/yaml_cpp_vendor/lib:/opt/ros/foxy/opt/rviz_ogre_vendor/lib:/opt/ros/foxy/lib/x86_64-linux-gnu:/opt/ros/foxy/lib:/usr/local/cuda-11.2/lib64/:/usr/local/cuda-11.2/lib64/\n",
      "2025-01-23 16:13:17.135241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#all imports\n",
    "import os\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "sys.path.append('/opt/carla-simulator/PythonAPI/carla') # tweak to where you put carla\n",
    "from keras.models import load_model\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('10.8.179.139', 2000)\n",
    "# start a car\n",
    "world = client.get_world()\n",
    "\n",
    "#clean up\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic settings\n",
    "PREFERRED_SPEED = 30\n",
    "SPEED_THRESHOLD = 2 # defines when we get close to desired speed so we drop the speed\n",
    "\n",
    "# Max steering angle\n",
    "MAX_STEER_DEGREES = 40\n",
    "# This is max actual angle with Mini under steering input=1.0\n",
    "STEERING_CONVERSION = 75\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "# resize images before running thgem through the model\n",
    "# this is the same as when yo train the model\n",
    "HEIGHT = 66\n",
    "WIDTH = 200\n",
    "\n",
    "#adding params to display text to image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# org - defining lines to display telemetry values on the screen\n",
    "org = (30, 30) # this line will be used to show current speed\n",
    "org2 = (30, 50) # this line will be used for future steering angle\n",
    "org3 = (30, 70) # and another line for future telemetry outputs\n",
    "org4 = (30, 90) # and another line for future telemetry outputs\n",
    "org3 = (30, 110) # and another line for future telemetry outputs\n",
    "fontScale = 0.5\n",
    "# white color\n",
    "color = (255, 255, 255)\n",
    "# Line thickness of 2 px\n",
    "thickness = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-23 16:13:34.426393: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-01-23 16:13:34.426502: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HASS-DESKTOP6): /proc/driver/nvidia/version does not exist\n",
      "2025-01-23 16:13:34.426959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# utility function for camera listening \n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "# utility function for camera listening \n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "# maintain speed function\n",
    "def maintain_speed(s):\n",
    "    ''' \n",
    "    this is a very simple function to maintan desired speed\n",
    "    s arg is actual current speed\n",
    "    '''\n",
    "    if s >= PREFERRED_SPEED:\n",
    "        return 0\n",
    "    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.9 # think of it as % of \"full gas\"\n",
    "    else:\n",
    "        return 0.4 # tweak this if the car is way over or under preferred speed \n",
    "\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "def get_proper_angle(car,wp_idx,rte):\n",
    "    '''\n",
    "    This function uses simple fuction above to get angle but for current\n",
    "    waypoint and a few more next waypoints to ensure we have not skipped\n",
    "    next waypoint so we avoid the car trying to turn back\n",
    "    '''\n",
    "    # create a list of angles to next 5 waypoints starting with current\n",
    "    next_angle_list = []\n",
    "    for i in range(10):\n",
    "        if wp_idx + i*3 <len(rte)-1:\n",
    "            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))\n",
    "    idx = 0\n",
    "    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:\n",
    "        idx +=1\n",
    "    return wp_idx+idx*3,next_angle_list[idx]  \n",
    "\n",
    "\n",
    "def draw_route(wp, route,seconds=3.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(10):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "def exit_clean():\n",
    "    #clean up\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    return None\n",
    "\n",
    "def predict_angle(RGB_im):\n",
    "    img = np.float32(RGB_im)\n",
    "    img = img /255              # normalize\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    angle = model(img,training=False)\n",
    "    return angle.numpy()[0][0] / math.pi\n",
    "\n",
    "\n",
    "# spawn the car\n",
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "#look for a blueprint of Tesla m3 car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "# load Nvidia DAVE-2 model\n",
    "MODEL_NAME = 'model/model.h5'\n",
    "model = load_model(MODEL_NAME,compile=False)\n",
    "model.compile()\n",
    "quit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predict: 44.156 \t Actual Angle: -0.000007\n",
      "Model predict: 43.853 \t Actual Angle: -0.000007\n",
      "Model predict: 43.943 \t Actual Angle: -0.000007\n",
      "Model predict: 45.803 \t Actual Angle: -0.000007\n",
      "Model predict: 43.329 \t Actual Angle: -0.000007\n",
      "Model predict: 43.592 \t Actual Angle: -0.000007\n",
      "Model predict: 44.664 \t Actual Angle: -0.000007\n",
      "Model predict: 43.842 \t Actual Angle: -0.000007\n",
      "Model predict: 44.703 \t Actual Angle: -0.000007\n",
      "Model predict: 44.890 \t Actual Angle: -0.000007\n",
      "Model predict: 44.136 \t Actual Angle: -0.000007\n",
      "Model predict: 43.219 \t Actual Angle: -0.000007\n",
      "Model predict: 44.250 \t Actual Angle: -0.000007\n",
      "Model predict: 44.756 \t Actual Angle: -0.000007\n",
      "Model predict: 43.991 \t Actual Angle: -0.000007\n",
      "Model predict: 43.951 \t Actual Angle: -0.000007\n",
      "Model predict: 44.557 \t Actual Angle: -0.000007\n",
      "Model predict: 44.390 \t Actual Angle: -0.000007\n",
      "Model predict: 43.115 \t Actual Angle: -0.000007\n",
      "Model predict: 43.979 \t Actual Angle: -0.000007\n",
      "Model predict: 45.050 \t Actual Angle: -0.000007\n",
      "Model predict: 44.542 \t Actual Angle: -0.000007\n",
      "Model predict: 44.992 \t Actual Angle: -0.000007\n",
      "Model predict: 45.357 \t Actual Angle: -0.000007\n",
      "Model predict: 44.643 \t Actual Angle: -0.000007\n",
      "Model predict: 43.504 \t Actual Angle: -0.000007\n",
      "Model predict: 43.505 \t Actual Angle: -0.000007\n",
      "Model predict: 44.288 \t Actual Angle: -0.000007\n",
      "Model predict: 43.480 \t Actual Angle: -0.000007\n",
      "Model predict: 44.459 \t Actual Angle: -0.000007\n",
      "Model predict: 45.236 \t Actual Angle: -0.000007\n",
      "Model predict: 46.282 \t Actual Angle: -0.000007\n",
      "Model predict: 43.636 \t Actual Angle: -0.000007\n",
      "Model predict: 44.337 \t Actual Angle: -0.000007\n",
      "Model predict: 44.500 \t Actual Angle: -0.000007\n",
      "Model predict: 44.239 \t Actual Angle: -0.000007\n",
      "Model predict: 44.449 \t Actual Angle: -0.000007\n",
      "Model predict: 43.228 \t Actual Angle: -0.000007\n",
      "Model predict: 44.438 \t Actual Angle: -0.000007\n",
      "Model predict: 43.709 \t Actual Angle: -0.000007\n",
      "Model predict: 43.569 \t Actual Angle: -0.017539\n",
      "Model predict: 48.473 \t Actual Angle: -0.183555\n",
      "Model predict: 49.475 \t Actual Angle: -0.466460\n",
      "Model predict: 41.368 \t Actual Angle: -0.833447\n",
      "Model predict: 6.688 \t Actual Angle: -1.325151\n",
      "Model predict: -7.313 \t Actual Angle: -1.852394\n",
      "Model predict: -15.499 \t Actual Angle: -2.124552\n",
      "Model predict: -12.926 \t Actual Angle: -2.120689\n",
      "Model predict: -15.301 \t Actual Angle: -1.993630\n",
      "Model predict: -14.474 \t Actual Angle: -1.811650\n",
      "Model predict: -12.603 \t Actual Angle: -1.576639\n",
      "Model predict: -1.670 \t Actual Angle: -1.367307\n",
      "Model predict: -3.866 \t Actual Angle: -1.190546\n",
      "Model predict: -7.614 \t Actual Angle: -1.068006\n",
      "Model predict: -7.215 \t Actual Angle: -0.985512\n",
      "Model predict: -13.363 \t Actual Angle: -0.859919\n",
      "Model predict: -4.294 \t Actual Angle: -0.717365\n",
      "Model predict: -2.624 \t Actual Angle: -0.475612\n",
      "Model predict: 25.494 \t Actual Angle: -0.339989\n",
      "Model predict: 16.515 \t Actual Angle: -0.260145\n",
      "Model predict: 16.893 \t Actual Angle: -0.799096\n",
      "Model predict: 5.958 \t Actual Angle: -1.167989\n",
      "Model predict: -11.463 \t Actual Angle: -1.626086\n",
      "Model predict: -11.364 \t Actual Angle: -1.814365\n",
      "Model predict: -11.789 \t Actual Angle: -1.773534\n",
      "Model predict: -12.308 \t Actual Angle: -1.642716\n",
      "Model predict: -10.000 \t Actual Angle: -1.307131\n",
      "Model predict: -10.468 \t Actual Angle: -1.113520\n",
      "Model predict: -3.774 \t Actual Angle: -0.926574\n",
      "Model predict: 5.621 \t Actual Angle: -0.788526\n",
      "Model predict: 14.158 \t Actual Angle: -0.736923\n",
      "Model predict: 10.591 \t Actual Angle: -0.833206\n",
      "Model predict: 12.307 \t Actual Angle: -1.073457\n",
      "Model predict: 3.265 \t Actual Angle: -1.315169\n",
      "Model predict: -8.603 \t Actual Angle: -1.570188\n",
      "Model predict: -10.474 \t Actual Angle: -1.699373\n",
      "Model predict: -11.981 \t Actual Angle: -1.667026\n",
      "Model predict: -12.621 \t Actual Angle: -1.538287\n",
      "Model predict: -12.046 \t Actual Angle: -1.346403\n",
      "Model predict: -11.017 \t Actual Angle: -1.018210\n",
      "Model predict: -3.492 \t Actual Angle: -0.647861\n",
      "Model predict: 2.348 \t Actual Angle: -0.447150\n",
      "Model predict: -4.664 \t Actual Angle: -0.347286\n",
      "Model predict: -6.254 \t Actual Angle: -0.347916\n",
      "Model predict: -12.152 \t Actual Angle: -0.295407\n",
      "Model predict: -12.309 \t Actual Angle: -0.170125\n",
      "Model predict: -12.440 \t Actual Angle: 0.032359\n",
      "Model predict: -10.079 \t Actual Angle: 0.343113\n",
      "Model predict: -3.133 \t Actual Angle: 0.588420\n",
      "Model predict: -6.140 \t Actual Angle: 0.819928\n",
      "Model predict: -13.239 \t Actual Angle: 0.965656\n",
      "Model predict: -13.127 \t Actual Angle: 1.107952\n",
      "Model predict: -13.224 \t Actual Angle: 1.381272\n",
      "Model predict: -13.132 \t Actual Angle: 1.673916\n",
      "Model predict: -12.432 \t Actual Angle: 1.964652\n",
      "Model predict: -11.823 \t Actual Angle: 2.264648\n",
      "Model predict: -10.222 \t Actual Angle: 2.551152\n",
      "Model predict: -4.874 \t Actual Angle: 2.864905\n",
      "Model predict: -9.647 \t Actual Angle: 3.275282\n",
      "Model predict: -10.209 \t Actual Angle: 3.482239\n",
      "Model predict: -7.490 \t Actual Angle: 3.747004\n",
      "Model predict: -9.807 \t Actual Angle: 3.946380\n",
      "Model predict: -9.162 \t Actual Angle: 4.200379\n",
      "Model predict: -9.379 \t Actual Angle: 4.505072\n",
      "Model predict: -8.542 \t Actual Angle: 4.830919\n",
      "Model predict: 1.276 \t Actual Angle: 5.148283\n",
      "Model predict: -1.181 \t Actual Angle: 5.455918\n",
      "Model predict: 0.642 \t Actual Angle: 5.427418\n",
      "Model predict: -2.859 \t Actual Angle: 5.599176\n",
      "Model predict: 1.546 \t Actual Angle: 5.775665\n",
      "Model predict: -2.914 \t Actual Angle: 5.976573\n",
      "Model predict: -1.540 \t Actual Angle: 6.146489\n",
      "Model predict: -2.190 \t Actual Angle: 6.502375\n",
      "Model predict: -1.367 \t Actual Angle: 6.285667\n",
      "Model predict: -1.410 \t Actual Angle: 6.469077\n",
      "Model predict: 0.875 \t Actual Angle: 6.691973\n",
      "Model predict: 1.523 \t Actual Angle: 6.927689\n",
      "Model predict: 1.890 \t Actual Angle: 7.120132\n",
      "Model predict: 2.118 \t Actual Angle: 7.290853\n",
      "Model predict: 2.043 \t Actual Angle: 7.465736\n",
      "Model predict: 1.673 \t Actual Angle: 7.042694\n",
      "Model predict: 2.161 \t Actual Angle: 7.170215\n",
      "Model predict: 1.799 \t Actual Angle: 7.344644\n",
      "Model predict: 2.223 \t Actual Angle: 7.499998\n",
      "Model predict: 2.248 \t Actual Angle: 7.657288\n",
      "Model predict: 4.056 \t Actual Angle: 7.862927\n",
      "Model predict: 3.542 \t Actual Angle: 7.367391\n",
      "Model predict: 2.156 \t Actual Angle: 7.484187\n",
      "Model predict: 2.296 \t Actual Angle: 7.604989\n",
      "Model predict: 2.072 \t Actual Angle: 7.773768\n",
      "Model predict: 2.238 \t Actual Angle: 7.935734\n",
      "Model predict: 2.222 \t Actual Angle: 8.138829\n",
      "Model predict: 2.169 \t Actual Angle: 8.348648\n",
      "Model predict: 2.185 \t Actual Angle: 7.713373\n",
      "Model predict: 2.223 \t Actual Angle: 7.877344\n",
      "Model predict: 2.210 \t Actual Angle: 8.063342\n",
      "Model predict: 2.177 \t Actual Angle: 8.283314\n",
      "Model predict: 1.606 \t Actual Angle: 8.497008\n",
      "Model predict: 1.820 \t Actual Angle: 8.723913\n",
      "Model predict: 1.130 \t Actual Angle: 8.023755\n",
      "Model predict: 1.039 \t Actual Angle: 8.214069\n",
      "Model predict: 0.925 \t Actual Angle: 8.413355\n",
      "Model predict: -0.404 \t Actual Angle: 8.705125\n",
      "Model predict: -1.886 \t Actual Angle: 8.956141\n",
      "Model predict: -4.236 \t Actual Angle: 9.251905\n",
      "Model predict: -4.199 \t Actual Angle: 8.750235\n",
      "Model predict: -4.897 \t Actual Angle: 9.085223\n",
      "Model predict: -2.790 \t Actual Angle: 9.458440\n",
      "Model predict: -2.706 \t Actual Angle: 9.854159\n",
      "Model predict: 2.084 \t Actual Angle: 10.249969\n",
      "Model predict: -2.083 \t Actual Angle: 9.885704\n",
      "Model predict: 2.332 \t Actual Angle: 10.149778\n",
      "Model predict: 5.949 \t Actual Angle: 10.462868\n",
      "Model predict: 3.960 \t Actual Angle: 10.769513\n",
      "Model predict: 18.885 \t Actual Angle: 11.079164\n",
      "Model predict: 17.212 \t Actual Angle: 10.637417\n",
      "Model predict: 3.468 \t Actual Angle: 10.711889\n",
      "Model predict: 2.457 \t Actual Angle: 10.704143\n",
      "Model predict: 5.723 \t Actual Angle: 10.799879\n",
      "Model predict: 0.864 \t Actual Angle: 11.036567\n",
      "Model predict: 15.009 \t Actual Angle: 11.262066\n",
      "Model predict: 14.170 \t Actual Angle: 10.829575\n",
      "Model predict: 15.279 \t Actual Angle: 10.989771\n",
      "Model predict: 15.594 \t Actual Angle: 11.063550\n",
      "Model predict: 16.098 \t Actual Angle: 11.087514\n",
      "Model predict: 15.707 \t Actual Angle: 11.097217\n",
      "Model predict: 13.478 \t Actual Angle: 10.460603\n",
      "Model predict: 0.997 \t Actual Angle: 10.436250\n",
      "Model predict: -8.080 \t Actual Angle: 10.420385\n",
      "Model predict: -5.289 \t Actual Angle: 10.563323\n",
      "Model predict: 18.509 \t Actual Angle: 10.974376\n",
      "Model predict: 15.902 \t Actual Angle: 11.352638\n",
      "Model predict: 18.394 \t Actual Angle: 11.023820\n",
      "Model predict: 17.809 \t Actual Angle: 11.159263\n",
      "Model predict: 17.619 \t Actual Angle: 11.168606\n",
      "Model predict: 19.165 \t Actual Angle: 11.129536\n",
      "Model predict: 16.792 \t Actual Angle: 11.071593\n",
      "Model predict: 8.631 \t Actual Angle: 10.471674\n",
      "Model predict: 15.347 \t Actual Angle: 10.384574\n",
      "Model predict: 13.290 \t Actual Angle: 10.377764\n",
      "Model predict: 22.556 \t Actual Angle: 10.381800\n",
      "Model predict: 26.199 \t Actual Angle: 10.380455\n",
      "Model predict: 24.172 \t Actual Angle: 10.311534\n",
      "Model predict: 30.609 \t Actual Angle: 9.629431\n",
      "Model predict: 33.453 \t Actual Angle: 9.362151\n",
      "Model predict: 36.416 \t Actual Angle: 9.013700\n",
      "Model predict: 37.186 \t Actual Angle: 8.546855\n",
      "Model predict: 48.819 \t Actual Angle: 8.016402\n",
      "Model predict: 47.862 \t Actual Angle: 7.137217\n",
      "Model predict: 52.224 \t Actual Angle: 6.185527\n",
      "Model predict: 62.391 \t Actual Angle: 5.608777\n",
      "Model predict: 55.969 \t Actual Angle: 4.665035\n",
      "Model predict: 60.433 \t Actual Angle: 3.626853\n",
      "Model predict: 36.735 \t Actual Angle: 2.075968\n",
      "Model predict: 45.162 \t Actual Angle: 0.722416\n",
      "Model predict: 2.173 \t Actual Angle: -0.615771\n",
      "Model predict: 2.203 \t Actual Angle: -1.800627\n",
      "Model predict: 1.496 \t Actual Angle: -2.518245\n",
      "Model predict: 1.736 \t Actual Angle: -2.631754\n",
      "Model predict: 1.588 \t Actual Angle: -2.813740\n",
      "Model predict: 1.972 \t Actual Angle: -2.942604\n",
      "Model predict: 1.923 \t Actual Angle: -3.134897\n",
      "Model predict: 1.894 \t Actual Angle: -2.814472\n",
      "Model predict: 2.105 \t Actual Angle: -2.907743\n",
      "Model predict: 2.217 \t Actual Angle: -3.041119\n",
      "Model predict: 2.226 \t Actual Angle: -3.175227\n",
      "Model predict: 2.212 \t Actual Angle: -3.330350\n",
      "Model predict: 2.222 \t Actual Angle: -3.461988\n",
      "Model predict: 2.227 \t Actual Angle: -2.903751\n",
      "Model predict: 2.201 \t Actual Angle: -3.031228\n",
      "Model predict: 2.246 \t Actual Angle: -3.174211\n",
      "Model predict: 2.504 \t Actual Angle: -3.326862\n",
      "Model predict: 2.212 \t Actual Angle: -3.493486\n",
      "Model predict: 2.094 \t Actual Angle: -2.775897\n",
      "Model predict: 2.180 \t Actual Angle: -2.929593\n",
      "Model predict: 1.851 \t Actual Angle: -3.094791\n",
      "Model predict: 1.447 \t Actual Angle: -3.252809\n",
      "Model predict: 2.049 \t Actual Angle: -3.400586\n",
      "Model predict: 1.558 \t Actual Angle: -2.527169\n",
      "Model predict: 0.974 \t Actual Angle: -2.640895\n",
      "Model predict: 0.869 \t Actual Angle: -2.762985\n",
      "Model predict: 1.750 \t Actual Angle: -2.885265\n",
      "Model predict: 0.612 \t Actual Angle: -3.026714\n",
      "Model predict: 0.244 \t Actual Angle: -2.032167\n",
      "Model predict: 0.803 \t Actual Angle: -2.129642\n",
      "Model predict: 1.343 \t Actual Angle: -2.216721\n",
      "Model predict: 0.668 \t Actual Angle: -2.294556\n",
      "Model predict: -0.039 \t Actual Angle: -2.381501\n",
      "Model predict: -0.069 \t Actual Angle: -1.278833\n",
      "Model predict: 1.162 \t Actual Angle: -1.325328\n",
      "Model predict: 0.920 \t Actual Angle: -1.366348\n",
      "Model predict: 0.791 \t Actual Angle: -1.421546\n",
      "Model predict: 1.581 \t Actual Angle: -1.482510\n",
      "Model predict: 1.680 \t Actual Angle: -1.544261\n",
      "Model predict: 1.467 \t Actual Angle: -0.363242\n",
      "Model predict: 1.974 \t Actual Angle: -0.412263\n",
      "Model predict: 1.444 \t Actual Angle: -0.468584\n",
      "Model predict: 1.902 \t Actual Angle: -0.524880\n",
      "Model predict: 2.204 \t Actual Angle: -0.582661\n",
      "Model predict: 2.217 \t Actual Angle: 0.626245\n",
      "Model predict: 2.213 \t Actual Angle: 0.598090\n",
      "Model predict: 2.214 \t Actual Angle: 0.566822\n",
      "Model predict: 2.218 \t Actual Angle: 0.530080\n",
      "Model predict: 2.218 \t Actual Angle: 0.494893\n",
      "Model predict: 2.219 \t Actual Angle: 1.713511\n",
      "Model predict: 2.219 \t Actual Angle: 1.712084\n",
      "Model predict: 2.217 \t Actual Angle: 1.711997\n",
      "Model predict: 2.186 \t Actual Angle: 1.712666\n",
      "Model predict: 2.218 \t Actual Angle: 1.714990\n",
      "Model predict: 2.218 \t Actual Angle: 2.932799\n",
      "Model predict: 2.219 \t Actual Angle: 2.971363\n",
      "Model predict: 2.219 \t Actual Angle: 3.006644\n",
      "Model predict: 2.219 \t Actual Angle: 3.046294\n",
      "Model predict: 2.219 \t Actual Angle: 3.090217\n",
      "Model predict: 2.220 \t Actual Angle: 3.138444\n",
      "Model predict: 2.221 \t Actual Angle: 4.361876\n",
      "Model predict: 2.252 \t Actual Angle: 4.424386\n",
      "Model predict: 2.587 \t Actual Angle: 4.522949\n",
      "Model predict: 3.408 \t Actual Angle: 4.648103\n",
      "Model predict: 11.940 \t Actual Angle: 4.720376\n",
      "Model predict: 25.788 \t Actual Angle: 5.881276\n",
      "Model predict: 34.430 \t Actual Angle: 5.879522\n",
      "Model predict: 51.284 \t Actual Angle: 5.729421\n",
      "Model predict: 47.363 \t Actual Angle: 5.342035\n",
      "Model predict: 56.446 \t Actual Angle: 4.689629\n",
      "Model predict: 65.022 \t Actual Angle: 4.881918\n",
      "Model predict: 51.454 \t Actual Angle: 3.849615\n",
      "Model predict: 29.097 \t Actual Angle: 2.487516\n",
      "Model predict: 10.139 \t Actual Angle: 1.222187\n",
      "Model predict: 4.317 \t Actual Angle: 0.310543\n",
      "Model predict: 1.682 \t Actual Angle: 0.859709\n",
      "Model predict: 2.168 \t Actual Angle: 0.547334\n",
      "Model predict: 2.233 \t Actual Angle: 0.390202\n",
      "Model predict: 2.280 \t Actual Angle: 0.325569\n",
      "Model predict: 2.260 \t Actual Angle: 0.248967\n",
      "Model predict: 2.296 \t Actual Angle: 1.377760\n",
      "Model predict: 2.349 \t Actual Angle: 1.358710\n",
      "Model predict: 2.417 \t Actual Angle: 1.341227\n",
      "Model predict: 3.292 \t Actual Angle: 1.325988\n",
      "Model predict: 2.550 \t Actual Angle: 1.309195\n",
      "Model predict: 2.554 \t Actual Angle: 2.462833\n",
      "Model predict: 2.643 \t Actual Angle: 2.442709\n",
      "Model predict: 2.580 \t Actual Angle: 2.460582\n",
      "Model predict: 2.274 \t Actual Angle: 2.494764\n",
      "Model predict: 2.373 \t Actual Angle: 2.494103\n",
      "Model predict: 2.509 \t Actual Angle: 3.660668\n",
      "Model predict: 2.284 \t Actual Angle: 3.721229\n",
      "Model predict: 2.238 \t Actual Angle: 3.784683\n",
      "Model predict: 2.256 \t Actual Angle: 3.852851\n",
      "Model predict: 2.450 \t Actual Angle: 3.947098\n",
      "Model predict: 2.530 \t Actual Angle: 5.071030\n",
      "Model predict: 2.196 \t Actual Angle: 5.174811\n",
      "Model predict: 7.952 \t Actual Angle: 5.283277\n",
      "Model predict: 9.990 \t Actual Angle: 5.401964\n",
      "Model predict: 12.107 \t Actual Angle: 5.480456\n",
      "Model predict: 30.155 \t Actual Angle: 6.448618\n",
      "Model predict: 32.022 \t Actual Angle: 6.397243\n",
      "Model predict: 25.758 \t Actual Angle: 6.204318\n",
      "Model predict: 30.161 \t Actual Angle: 5.779053\n",
      "Model predict: 24.648 \t Actual Angle: 5.340774\n",
      "Model predict: 2.142 \t Actual Angle: 5.784818\n",
      "Model predict: 16.436 \t Actual Angle: 5.393633\n",
      "Model predict: 17.748 \t Actual Angle: 5.155163\n",
      "Model predict: 11.055 \t Actual Angle: 5.024785\n",
      "Model predict: 12.092 \t Actual Angle: 4.810955\n",
      "Model predict: 3.137 \t Actual Angle: 5.495323\n",
      "Model predict: 3.854 \t Actual Angle: 5.357392\n",
      "Model predict: 2.989 \t Actual Angle: 5.340974\n",
      "Model predict: 5.796 \t Actual Angle: 5.415380\n",
      "Model predict: 9.122 \t Actual Angle: 6.337450\n",
      "Model predict: 8.617 \t Actual Angle: 6.441180\n",
      "Model predict: 8.454 \t Actual Angle: 6.457740\n",
      "Model predict: 9.258 \t Actual Angle: 6.462001\n",
      "Model predict: 9.624 \t Actual Angle: 6.460883\n",
      "Model predict: 10.109 \t Actual Angle: 7.324724\n",
      "Model predict: 9.421 \t Actual Angle: 7.323347\n",
      "Model predict: 4.729 \t Actual Angle: 7.323875\n",
      "Model predict: 3.060 \t Actual Angle: 7.341023\n",
      "Model predict: 2.390 \t Actual Angle: 7.422154\n",
      "Model predict: 2.186 \t Actual Angle: 8.392413\n",
      "Model predict: 2.224 \t Actual Angle: 8.567255\n",
      "Model predict: 2.179 \t Actual Angle: 8.779536\n",
      "Model predict: 2.181 \t Actual Angle: 9.078986\n",
      "Model predict: 2.210 \t Actual Angle: 9.317286\n",
      "Model predict: 2.218 \t Actual Angle: 10.341200\n",
      "Model predict: 2.228 \t Actual Angle: 10.614669\n",
      "Model predict: 2.298 \t Actual Angle: 10.943351\n",
      "Model predict: 2.214 \t Actual Angle: 11.317696\n",
      "Model predict: 2.293 \t Actual Angle: 12.336041\n",
      "Model predict: 2.520 \t Actual Angle: 12.663059\n",
      "Model predict: 2.629 \t Actual Angle: 12.994014\n",
      "Model predict: 2.452 \t Actual Angle: 13.354030\n",
      "Model predict: 2.752 \t Actual Angle: 13.777954\n",
      "Model predict: 2.911 \t Actual Angle: 14.685840\n",
      "Model predict: 2.499 \t Actual Angle: 15.112205\n",
      "Model predict: 2.798 \t Actual Angle: 15.497119\n",
      "Model predict: 2.897 \t Actual Angle: 15.951382\n",
      "Model predict: 2.678 \t Actual Angle: 16.464501\n",
      "Model predict: 2.407 \t Actual Angle: 17.424851\n",
      "Model predict: 3.333 \t Actual Angle: 17.927957\n",
      "Model predict: 3.933 \t Actual Angle: 18.472501\n",
      "Model predict: 4.696 \t Actual Angle: 19.040803\n",
      "Model predict: 5.125 \t Actual Angle: 19.685161\n",
      "Model predict: 4.472 \t Actual Angle: 20.191908\n",
      "Model predict: 5.403 \t Actual Angle: 20.738374\n",
      "Model predict: 3.547 \t Actual Angle: 21.266199\n",
      "Model predict: 3.535 \t Actual Angle: 21.802138\n",
      "Model predict: 2.504 \t Actual Angle: 22.501901\n",
      "Model predict: 4.073 \t Actual Angle: 22.963759\n",
      "Model predict: 3.561 \t Actual Angle: 23.621131\n",
      "Model predict: 3.639 \t Actual Angle: 24.310432\n",
      "Model predict: 4.512 \t Actual Angle: 25.036046\n",
      "Model predict: 3.662 \t Actual Angle: 25.826059\n",
      "Model predict: 9.752 \t Actual Angle: 26.009277\n",
      "Model predict: 10.209 \t Actual Angle: 26.732394\n",
      "Model predict: 6.560 \t Actual Angle: 27.428650\n",
      "Model predict: 12.567 \t Actual Angle: 28.122037\n",
      "Model predict: 11.333 \t Actual Angle: 28.855987\n",
      "Model predict: 13.701 \t Actual Angle: 28.707794\n",
      "Model predict: 3.093 \t Actual Angle: 29.422296\n",
      "Model predict: 2.344 \t Actual Angle: 30.041833\n",
      "Model predict: 2.201 \t Actual Angle: 31.165308\n",
      "Model predict: 2.196 \t Actual Angle: 32.129218\n",
      "Model predict: 2.195 \t Actual Angle: 31.837030\n",
      "Model predict: 2.205 \t Actual Angle: 32.642615\n",
      "Model predict: 2.357 \t Actual Angle: 33.640756\n",
      "Model predict: 3.951 \t Actual Angle: 34.634933\n",
      "Model predict: 4.029 \t Actual Angle: 35.774635\n",
      "Model predict: 4.485 \t Actual Angle: 35.394723\n",
      "Model predict: 3.264 \t Actual Angle: 36.504136\n",
      "Model predict: 2.478 \t Actual Angle: 37.466062\n",
      "Model predict: 2.549 \t Actual Angle: 38.579841\n",
      "Model predict: 2.381 \t Actual Angle: 39.732916\n",
      "Model predict: 2.252 \t Actual Angle: 36.713024\n",
      "Model predict: 2.244 \t Actual Angle: 37.336931\n",
      "Model predict: 2.261 \t Actual Angle: 38.081763\n",
      "Model predict: 1.857 \t Actual Angle: 38.956989\n",
      "Model predict: 1.557 \t Actual Angle: 38.274353\n",
      "Model predict: 1.609 \t Actual Angle: 38.959401\n",
      "Model predict: 1.205 \t Actual Angle: 39.650746\n",
      "Model predict: 1.304 \t Actual Angle: 39.858093\n",
      "Model predict: 1.325 \t Actual Angle: 51.625424\n",
      "Model predict: 0.787 \t Actual Angle: 81.774515\n",
      "Model predict: 0.607 \t Actual Angle: 103.274845\n",
      "Model predict: -0.145 \t Actual Angle: 115.617133\n",
      "Model predict: -0.777 \t Actual Angle: 135.908519\n",
      "Model predict: -1.493 \t Actual Angle: 154.732930\n",
      "Model predict: -0.429 \t Actual Angle: 158.515593\n",
      "Model predict: -1.624 \t Actual Angle: 155.755148\n"
     ]
    }
   ],
   "source": [
    "# main loop\n",
    "while True:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    "    #setting RGB Camera - this follow the approach explained in a Carla video\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '360')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3))} # 3 channels for RGB\n",
    "\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('RGB Camera', 800, 450)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    # getting a random route for the car\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    curr_wp = 5 #we will be tracking waypoints in the route and switch to next one when we get close to current one\n",
    "    predicted_angle = 0\n",
    "    PREFERRED_SPEED = 20 # setting speed at start of new route\n",
    "    \n",
    "    spectator = world.get_spectator()\n",
    "    spectator_pos = carla.Transform(start_point.location + carla.Location(x=-20,y=10,z=10),\n",
    "                                carla.Rotation(yaw = start_point.rotation.yaw -155))\n",
    "    spectator.set_transform(spectator_pos)\n",
    "\n",
    "    while curr_wp<len(route)-1:\n",
    "        # Carla Tick\n",
    "        world.tick()\n",
    "        draw_route(curr_wp, route,1)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            quit = True\n",
    "            exit_clean()\n",
    "            cv2.imwrite('final_%3f_%3s.png' % (steer_input,round(predicted_angle,0)), image)\n",
    "            break\n",
    "\n",
    "        image = camera_data['image']\n",
    "        image_show = image\n",
    "        image = cv2.resize(image, (WIDTH,HEIGHT), interpolation=cv2.INTER_AREA) # to get better img quality\n",
    "\n",
    "\n",
    "        # Spectator Update\n",
    "        spectator_transform = vehicle.get_transform()\n",
    "        spectator_transform.location += carla.Location(x=0, y=0, z=15)\n",
    "        spectator_transform.rotation.yaw += -15  # left\n",
    "        spectator_transform.rotation.pitch = -60 # downward\n",
    "        spectator.set_transform(spectator_transform)\n",
    "        \n",
    "        \n",
    "        if curr_wp >=len(route)-10: # within 10 points of end, the route is done\n",
    "            PREFERRED_SPEED = 0 # seeting speed to 0 after completing one route\n",
    "            exit_clean()\n",
    "            break\n",
    "        while curr_wp<len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:\n",
    "            curr_wp +=1 #move to next wp if we are too close\n",
    "        curr_wp, predicted_angle = get_proper_angle(vehicle,curr_wp,route)\n",
    "        \n",
    "        v = vehicle.get_velocity()\n",
    "        speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "\n",
    "        # estimated_throttle = maintain_speed(speed)\n",
    "        # use the model to predict steering - predictions are expected to be in -1 to +1\n",
    "        steer_input = predict_angle(image)\n",
    "        throttle = 0.3 - 0.09 * abs(steer_input)\n",
    "\n",
    "        \n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=float(throttle), steer=float(steer_input)))\n",
    "\n",
    "        image_show = cv2.UMat(image_show)\n",
    "        image_show = cv2.putText(image_show, 'Speed: '+str(int(speed))+' kmh', org, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        image_show = cv2.putText(image_show, 'Actual Angle: '+ str(int(predicted_angle)), org2, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        image_show = cv2.putText(image_show, 'Model predict: '+str(float(steer_input)), org3, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        print(\"Model predict: %.3f \\t Actual Angle: %f\" % (steer_input * 180, predicted_angle))\n",
    "        cv2.imshow('RGB Camera', cv2.resize(image_show, (800, 398)))\n",
    "    if quit:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1 (Conv2D)              (None, 31, 98, 24)        1824      \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 14, 47, 36)        21636     \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 5, 22, 48)         43248     \n",
      "                                                                 \n",
      " conv4 (Conv2D)              (None, 3, 20, 64)         27712     \n",
      "                                                                 \n",
      " conv5 (Conv2D)              (None, 1, 18, 64)         36928     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 100)               115300    \n",
      "                                                                 \n",
      " do1 (Dropout)               (None, 100)               0         \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 50)                5050      \n",
      "                                                                 \n",
      " do2 (Dropout)               (None, 50)                0         \n",
      "                                                                 \n",
      " fc3 (Dense)                 (None, 10)                510       \n",
      "                                                                 \n",
      " do3 (Dropout)               (None, 10)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 252,219\n",
      "Trainable params: 252,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name : conv1      layer output shape : (None, 31, 98, 24)   {'name': 'conv1', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 66, 200, 3), 'filters': 24, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : conv2      layer output shape : (None, 14, 47, 36)   {'name': 'conv2', 'trainable': True, 'dtype': 'float32', 'filters': 36, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : conv3      layer output shape : (None, 5, 22, 48)    {'name': 'conv3', 'trainable': True, 'dtype': 'float32', 'filters': 48, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : conv4      layer output shape : (None, 3, 20, 64)    {'name': 'conv4', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : conv5      layer output shape : (None, 1, 18, 64)    {'name': 'conv5', 'trainable': True, 'dtype': 'float32', 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : flatten_5  layer output shape : (None, 1152)         {'name': 'flatten_5', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}\n",
      "Layer name : fc1        layer output shape : (None, 100)          {'name': 'fc1', 'trainable': True, 'dtype': 'float32', 'units': 100, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : do1        layer output shape : (None, 100)          {'name': 'do1', 'trainable': True, 'dtype': 'float32', 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "Layer name : fc2        layer output shape : (None, 50)           {'name': 'fc2', 'trainable': True, 'dtype': 'float32', 'units': 50, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : do2        layer output shape : (None, 50)           {'name': 'do2', 'trainable': True, 'dtype': 'float32', 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "Layer name : fc3        layer output shape : (None, 10)           {'name': 'fc3', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'elu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "Layer name : do3        layer output shape : (None, 10)           {'name': 'do3', 'trainable': True, 'dtype': 'float32', 'rate': 0.25, 'noise_shape': None, 'seed': None}\n",
      "Layer name : dense_6    layer output shape : (None, 1)            {'name': 'dense_6', 'trainable': True, 'dtype': 'float32', 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    print(f'Layer name : {layer.name:<10} layer output shape : {str(layer.output_shape):<20} {layer.get_config()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name : conv1/kernel:0       weight shape : (5, 5, 3, 24)  \n",
      "Layer name : conv1/bias:0         weight shape : (24,)          \n",
      "Layer name : conv2/kernel:0       weight shape : (5, 5, 24, 36) \n",
      "Layer name : conv2/bias:0         weight shape : (36,)          \n",
      "Layer name : conv3/kernel:0       weight shape : (5, 5, 36, 48) \n",
      "Layer name : conv3/bias:0         weight shape : (48,)          \n",
      "Layer name : conv4/kernel:0       weight shape : (3, 3, 48, 64) \n",
      "Layer name : conv4/bias:0         weight shape : (64,)          \n",
      "Layer name : conv5/kernel:0       weight shape : (3, 3, 64, 64) \n",
      "Layer name : conv5/bias:0         weight shape : (64,)          \n",
      "Layer name : fc1/kernel:0         weight shape : (1152, 100)    \n",
      "Layer name : fc1/bias:0           weight shape : (100,)         \n",
      "Layer name : fc2/kernel:0         weight shape : (100, 50)      \n",
      "Layer name : fc2/bias:0           weight shape : (50,)          \n",
      "Layer name : fc3/kernel:0         weight shape : (50, 10)       \n",
      "Layer name : fc3/bias:0           weight shape : (10,)          \n",
      "Layer name : dense_6/kernel:0     weight shape : (10, 1)        \n",
      "Layer name : dense_6/bias:0       weight shape : (1,)           \n"
     ]
    }
   ],
   "source": [
    "for weight in model.weights:\n",
    "    print(f'Layer name : {weight.name:<20} weight shape : {str(weight.shape):<15}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "# 입력 이미지 로드 및 전처리\n",
    "image = cv2.imread('lane_detect.png')\n",
    "image = np.float32(image)\n",
    "image = image / 255\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "# 특징 맵 추출\n",
    "layer_outputs = [layer.output for layer in model.layers[:5]]  # 처음 5개 레이어의 출력\n",
    "activation_model = keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
    "activations = activation_model.predict(image)\n",
    "\n",
    "# 레이어 이름 설정\n",
    "layer_names = []\n",
    "for layer in model.layers[:5]:\n",
    "    layer_names.append(layer.name)\n",
    "\n",
    "# 특징 맵 시각화\n",
    "for layer_name, activation in zip(layer_names, activations):\n",
    "    n_features = activation.shape[-1]  # 특징 맵 개수 (채널 수)\n",
    "    height = activation.shape[1] # 특징 맵 높이\n",
    "    width = activation.shape[2]  # 특징 맵 너비\n",
    "\n",
    "    # 한 행에 표시할 이미지 개수 설정 (최대 16, 특징 맵 개수가 16보다 작으면 그 개수만큼)\n",
    "    images_per_row = min(n_features, 16)\n",
    "\n",
    "    # 열 개수 계산\n",
    "    n_cols = n_features // images_per_row\n",
    "    if n_features % images_per_row != 0:\n",
    "        n_cols += 1\n",
    "\n",
    "    # 이미지들을 쌓을 그리드 초기화\n",
    "    display_grid = np.zeros((height * n_cols, width * images_per_row), dtype=np.float32)\n",
    "\n",
    "    # 각 필터를 그리드에 채우기\n",
    "    for col in range(n_cols):\n",
    "        for row in range(images_per_row):\n",
    "            channel_index = col * images_per_row + row\n",
    "            if channel_index < n_features:\n",
    "                channel_image = activation[0, :, :, channel_index]\n",
    "                # 채널 정규화\n",
    "                channel_image -= channel_image.mean()\n",
    "                if channel_image.std() > 0: # 0으로 나누는 에러 방지\n",
    "                  channel_image /= channel_image.std()\n",
    "                channel_image *= 64\n",
    "                channel_image += 128\n",
    "                channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n",
    "                # 그리드에 채널 이미지 배치\n",
    "                display_grid[\n",
    "                    col * height : (col + 1) * height,\n",
    "                    row * width : (row + 1) * width,\n",
    "                ] = channel_image\n",
    "\n",
    "    # 그리드 스케일 조정\n",
    "    scale = 1.0 / max(width, height)\n",
    "    # OpenCV를 사용하여 특징 맵 출력\n",
    "    cv2.namedWindow(layer_name, cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(layer_name, int(scale * display_grid.shape[1] * 20), int(scale * display_grid.shape[0] * 20)) # 가로 세로 비율 유지하면서 크기 조정\n",
    "    cv2.imshow(layer_name, display_grid)\n",
    "    while True:\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            cv2.destroyAllWindows()\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-0.9.13-py3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
