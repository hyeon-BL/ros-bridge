{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all imports\n",
    "import os\n",
    "import carla #the sim library itself\n",
    "import time # to set a delay after each photo\n",
    "import cv2 #to work with images from cameras\n",
    "import numpy as np #in this example to change image representation - re-shaping\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "sys.path.append('/opt/carla-simulator/PythonAPI/carla') # tweak to where you put carla\n",
    "from keras.models import load_model\n",
    "from agents.navigation.global_route_planner import GlobalRoutePlanner\n",
    "from matplotlib import pyplot as plt \n",
    "\n",
    "# disable GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = carla.Client('10.8.179.139', 2000)\n",
    "# start a car\n",
    "world = client.get_world()\n",
    "\n",
    "#clean up\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define basic settings\n",
    "PREFERRED_SPEED = 30\n",
    "SPEED_THRESHOLD = 2 # defines when we get close to desired speed so we drop the speed\n",
    "\n",
    "# Max steering angle\n",
    "MAX_STEER_DEGREES = 40\n",
    "# This is max actual angle with Mini under steering input=1.0\n",
    "STEERING_CONVERSION = 75\n",
    "\n",
    "CAMERA_POS_Z = 1.3 \n",
    "CAMERA_POS_X = 1.4 \n",
    "\n",
    "# resize images before running thgem through the model\n",
    "# this is the same as when yo train the model\n",
    "HEIGHT = 66\n",
    "WIDTH = 200\n",
    "\n",
    "#adding params to display text to image\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "# org - defining lines to display telemetry values on the screen\n",
    "org = (30, 30) # this line will be used to show current speed\n",
    "org2 = (30, 50) # this line will be used for future steering angle\n",
    "org3 = (30, 70) # and another line for future telemetry outputs\n",
    "org4 = (30, 90) # and another line for future telemetry outputs\n",
    "org3 = (30, 110) # and another line for future telemetry outputs\n",
    "fontScale = 0.5\n",
    "# white color\n",
    "color = (255, 255, 255)\n",
    "# Line thickness of 2 px\n",
    "thickness = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 10:28:56.592156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:267] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2025-01-22 10:28:56.592266: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (HASS-DESKTOP6): /proc/driver/nvidia/version does not exist\n",
      "2025-01-22 10:28:56.597292: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# utility function for camera listening \n",
    "def camera_callback(image,data_dict):\n",
    "    data_dict['image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "# utility function for camera listening \n",
    "def sem_callback(image,data_dict):\n",
    "    ########## IMPORTANT CHANGE for Semantic camera ##############\n",
    "    image.convert(carla.ColorConverter.CityScapesPalette)\n",
    "    data_dict['sem_image'] = np.reshape(np.copy(image.raw_data),(image.height,image.width,4))[:, :, :3]\n",
    "\n",
    "# maintain speed function\n",
    "def maintain_speed(s):\n",
    "    ''' \n",
    "    this is a very simple function to maintan desired speed\n",
    "    s arg is actual current speed\n",
    "    '''\n",
    "    if s >= PREFERRED_SPEED:\n",
    "        return 0\n",
    "    elif s < PREFERRED_SPEED - SPEED_THRESHOLD:\n",
    "        return 0.9 # think of it as % of \"full gas\"\n",
    "    else:\n",
    "        return 0.4 # tweak this if the car is way over or under preferred speed \n",
    "\n",
    "\n",
    "# function to get angle between the car and target waypoint\n",
    "def get_angle(car,wp):\n",
    "    '''\n",
    "    this function returns degrees between the car's direction \n",
    "    and direction to a selected waypoint\n",
    "    '''\n",
    "    vehicle_pos = car.get_transform()\n",
    "    car_x = vehicle_pos.location.x\n",
    "    car_y = vehicle_pos.location.y\n",
    "    wp_x = wp.transform.location.x\n",
    "    wp_y = wp.transform.location.y\n",
    "    \n",
    "    # vector to waypoint\n",
    "    x = (wp_x - car_x)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    y = (wp_y - car_y)/((wp_y - car_y)**2 + (wp_x - car_x)**2)**0.5\n",
    "    \n",
    "    #car vector\n",
    "    car_vector = vehicle_pos.get_forward_vector()\n",
    "    degrees = math.degrees(np.arctan2(y, x) - np.arctan2(car_vector.y, car_vector.x))\n",
    "    # extra checks on predicted angle when values close to 360 degrees are returned\n",
    "    if degrees<-180:\n",
    "        degrees = degrees + 360\n",
    "    elif degrees > 180:\n",
    "        degrees = degrees - 360\n",
    "    return degrees\n",
    "\n",
    "def get_proper_angle(car,wp_idx,rte):\n",
    "    '''\n",
    "    This function uses simple fuction above to get angle but for current\n",
    "    waypoint and a few more next waypoints to ensure we have not skipped\n",
    "    next waypoint so we avoid the car trying to turn back\n",
    "    '''\n",
    "    # create a list of angles to next 5 waypoints starting with current\n",
    "    next_angle_list = []\n",
    "    for i in range(10):\n",
    "        if wp_idx + i*3 <len(rte)-1:\n",
    "            next_angle_list.append(get_angle(car,rte[wp_idx + i*3][0]))\n",
    "    idx = 0\n",
    "    while idx<len(next_angle_list)-2 and abs(next_angle_list[idx])>40:\n",
    "        idx +=1\n",
    "    return wp_idx+idx*3,next_angle_list[idx]  \n",
    "\n",
    "\n",
    "def draw_route(wp, route,seconds=3.0):\n",
    "    #draw the next few points route in sim window - Note it does not\n",
    "    # get into the camera of the car\n",
    "    if len(route)-wp <25: # route within 25 points from end is red\n",
    "        draw_colour = carla.Color(r=255, g=0, b=0)\n",
    "    else:\n",
    "        draw_colour = carla.Color(r=0, g=0, b=255)\n",
    "    for i in range(10):\n",
    "        if wp+i<len(route)-2:\n",
    "            world.debug.draw_string(route[wp+i][0].transform.location, '^', draw_shadow=False,\n",
    "                color=draw_colour, life_time=seconds,\n",
    "                persistent_lines=True)\n",
    "    return None\n",
    "\n",
    "\n",
    "def select_random_route(position,locs):\n",
    "    '''\n",
    "    retruns a random route for the car/veh\n",
    "    out of the list of possible locations locs\n",
    "    where distance is longer than 100 waypoints\n",
    "    '''    \n",
    "    point_a = position.location #we start at where the car is or last waypoint\n",
    "    sampling_resolution = 1\n",
    "    grp = GlobalRoutePlanner(world.get_map(), sampling_resolution)\n",
    "    # now let' pick the longest possible route\n",
    "    min_distance = 100\n",
    "    result_route = None\n",
    "    route_list = []\n",
    "    for loc in locs: # we start trying all spawn points \n",
    "                                #but we just exclude first at zero index\n",
    "        cur_route = grp.trace_route(point_a, loc.location)\n",
    "        if len(cur_route) > min_distance:\n",
    "            route_list.append(cur_route)\n",
    "    result_route = random.choice(route_list)\n",
    "    return result_route\n",
    "\n",
    "def exit_clean():\n",
    "    #clean up\n",
    "    cv2.destroyAllWindows()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    return None\n",
    "\n",
    "def predict_angle(sem_im):\n",
    "    # tweaks for prediction\n",
    "    img = np.float32(sem_im)\n",
    "    img = img /255\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    angle = model(img,training=False)\n",
    "    return  angle.numpy()[0][0]\n",
    "\n",
    "\n",
    "# spawn the car\n",
    "world = client.get_world()\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "#look for a blueprint of Tesla m3 car\n",
    "vehicle_bp = world.get_blueprint_library().filter('*model3*')\n",
    "\n",
    "# load Nvidia DAVE-2 model\n",
    "MODEL_NAME = 'model/model.h5'\n",
    "model = load_model(MODEL_NAME,compile=False)\n",
    "model.compile()\n",
    "quit = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main loop\n",
    "while True:\n",
    "    start_point = random.choice(spawn_points)\n",
    "    vehicle = world.try_spawn_actor(vehicle_bp[0], start_point)\n",
    "    time.sleep(2)\n",
    "    #setting RGB Camera - this follow the approach explained in a Carla video\n",
    "    camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')\n",
    "    camera_bp.set_attribute('image_size_x', '640') # this ratio works in CARLA 9.14 on Windows\n",
    "    camera_bp.set_attribute('image_size_y', '360')\n",
    "    camera_init_trans = carla.Transform(carla.Location(z=CAMERA_POS_Z,x=CAMERA_POS_X))\n",
    "    #this creates the camera in the sim\n",
    "    camera = world.spawn_actor(camera_bp,camera_init_trans,attach_to=vehicle)\n",
    "    image_w = camera_bp.get_attribute('image_size_x').as_int()\n",
    "    image_h = camera_bp.get_attribute('image_size_y').as_int()\n",
    "\n",
    "    camera_data = {'image': np.zeros((image_h,image_w,3))} # 3 channels for RGB\n",
    "\n",
    "    # this actually opens a live stream from the camera\n",
    "    camera.listen(lambda image: camera_callback(image,camera_data))\n",
    "    cv2.namedWindow('RGB Camera',cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow('RGB Camera', 800, 450)\n",
    "    cv2.imshow('RGB Camera',camera_data['image'])\n",
    "    # getting a random route for the car\n",
    "    route = select_random_route(start_point,spawn_points)\n",
    "    curr_wp = 5 #we will be tracking waypoints in the route and switch to next one when we get close to current one\n",
    "    predicted_angle = 0\n",
    "    PREFERRED_SPEED = 40 # setting speed at start of new route\n",
    "    \n",
    "    spectator = world.get_spectator()\n",
    "    spectator_pos = carla.Transform(start_point.location + carla.Location(x=-20,y=10,z=10),\n",
    "                                carla.Rotation(yaw = start_point.rotation.yaw -155))\n",
    "    spectator.set_transform(spectator_pos)\n",
    "\n",
    "    while curr_wp<len(route)-1:\n",
    "        # Carla Tick\n",
    "        world.tick()\n",
    "        draw_route(curr_wp, route,1)\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            quit = True\n",
    "            exit_clean()\n",
    "            break\n",
    "        image = camera_data['image']\n",
    "        image = cv2.resize(image, (WIDTH,HEIGHT))\n",
    "\n",
    "\n",
    "        # Spectator Update\n",
    "        spectator_transform = vehicle.get_transform()\n",
    "        spectator_transform.location += carla.Location(x=0, y=0, z=15)\n",
    "        spectator_transform.rotation.yaw += -15  # left\n",
    "        spectator_transform.rotation.pitch = -60 # downward\n",
    "        spectator.set_transform(spectator_transform)\n",
    "        \n",
    "        \n",
    "        if curr_wp >=len(route)-10: # within 10 points of end, the route is done\n",
    "            PREFERRED_SPEED = 0 # seeting speed to 0 after completing one route\n",
    "            exit_clean()\n",
    "            break\n",
    "        while curr_wp<len(route)-2 and vehicle.get_transform().location.distance(route[curr_wp][0].transform.location)<5:\n",
    "            curr_wp +=1 #move to next wp if we are too close\n",
    "        curr_wp, predicted_angle = get_proper_angle(vehicle,curr_wp,route)\n",
    "        \n",
    "        v = vehicle.get_velocity()\n",
    "        speed = round(3.6 * math.sqrt(v.x**2 + v.y**2 + v.z**2),0)\n",
    "\n",
    "        estimated_throttle = maintain_speed(speed)\n",
    "        # use the model to predict steering - predictions are expected to be in -1 to +1\n",
    "        steer_input = predict_angle(image)\n",
    "        \n",
    "        vehicle.apply_control(carla.VehicleControl(throttle=float(estimated_throttle), steer=float(steer_input)))\n",
    "\n",
    "        image = cv2.putText(image, 'Speed: '+str(int(speed))+' kmh', org2, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        image = cv2.putText(image, 'Actual Angle: '+ str(int(predicted_angle)), org2, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        image = cv2.putText(image, 'Model predict: '+str(int(steer_input)), org2, \n",
    "                        font, fontScale, color, thickness, cv2.LINE_AA)\n",
    "        cv2.imshow('RGB Camera',image)\n",
    "    if quit:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carla-0.9.13-py3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
